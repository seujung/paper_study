{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd ,nd, lr_scheduler\n",
    "from mxnet.gluon import nn, utils\n",
    "import mxnet.ndarray as F\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.HybridBlock):\n",
    "    def __init__(self,param,**kwargs):\n",
    "        super(Decoder,self).__init__(**kwargs)\n",
    "        self.num_channel = param['num_channel']\n",
    "        self.b_size = param['batch_size']\n",
    "        self.scale_size = param['scale_size']\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.l0 = nn.Dense(8*8*self.num_channel)\n",
    "            self.l1 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l2 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            #self.up1 = F.UpSampling(scale=2,sample_type='nearest')\n",
    "            self.l3 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l4 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            #self.up2 = F.UpSampling(scale=2,sample_type='nearest')\n",
    "            self.l5 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l6 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            #self.up3 = F.UpSampling(scale=2,sample_type='nearest')\n",
    "            self.l7 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l8 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l9 = nn.Conv2D(3,3,1,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.l0(x)\n",
    "        x = x.reshape((-1,self.num_channel,8,8)) ## reshape\n",
    "        \n",
    "        x = F.LeakyReLU(data=self.l1(x),act_type='elu')\n",
    "        x = F.LeakyReLU(data=self.l2(x),act_type='elu')\n",
    "        x = F.UpSampling(x,scale=2,sample_type='nearest')\n",
    "        \n",
    "        x = F.LeakyReLU(data=self.l3(x),act_type='elu')\n",
    "        x = F.LeakyReLU(data=self.l4(x),act_type='elu')\n",
    "        x = F.UpSampling(x,scale=2,sample_type='nearest')\n",
    "        \n",
    "        x = F.LeakyReLU(data=self.l5(x),act_type='elu')\n",
    "        x = F.LeakyReLU(data=self.l6(x),act_type='elu')\n",
    "        #x = F.UpSampling(x,scale=2,sample_type='nearest')\n",
    "        \n",
    "        x = F.LeakyReLU(data=self.l7(x),act_type='elu')\n",
    "        x = F.LeakyReLU(data=self.l8(x),act_type='elu')\n",
    "        x = F.LeakyReLU(data=self.l9(x),act_type='elu')\n",
    "        \n",
    "        x = F.tanh(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.HybridBlock):\n",
    "    def __init__(self,param,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.num_channel = param['num_channel']\n",
    "        self.b_size = param['batch_size']\n",
    "        self.scale_size = param['scale_size']\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.l0 = nn.Conv2D(3,3,1,1)\n",
    "            self.l1_1 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l1_2 = nn.Conv2D(self.num_channel,3,1,1)\n",
    "            self.l2 = nn.Conv2D(self.num_channel*2,3,1,1)\n",
    "            self.sub1 = nn.AvgPool2D(2,2)\n",
    "            \n",
    "            self.l3_1 = nn.Conv2D(self.num_channel*2,3,1,1)\n",
    "            self.l3_2 = nn.Conv2D(self.num_channel*2,3,1,1)\n",
    "            self.l4 = nn.Conv2D(self.num_channel*3,3,1,1)\n",
    "            self.sub2 = nn.AvgPool2D(2,2)\n",
    "            \n",
    "            if self.scale_size == 64 :\n",
    "                self.l5_1 = nn.Conv2D(self.num_channel*3,3,1,1)\n",
    "                self.l5_2 = nn.Conv2D(self.num_channel*3,3,1,1)\n",
    "                self.l6 = nn.Dense(8*8*3*self.num_channel)\n",
    "            \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.LeakyReLU(self.l0(x),act_type='elu')\n",
    "        x = F.LeakyReLU(self.l1_1(x),act_type='elu')\n",
    "        x = F.LeakyReLU(self.l1_2(x),act_type='elu')\n",
    "        x = F.LeakyReLU(self.l2(x),act_type='elu')\n",
    "        x = self.sub1(x)\n",
    "        \n",
    "        x = F.LeakyReLU(self.l3_1(x),act_type='elu')\n",
    "        x = F.LeakyReLU(self.l3_2(x),act_type='elu')\n",
    "        x = F.LeakyReLU(self.l4(x),act_type='elu')\n",
    "        x = self.sub2(x)\n",
    "        \n",
    "        if self.scale_size == 64 :\n",
    "            x = F.LeakyReLU(self.l5_1(x),act_type='elu')\n",
    "            x = F.LeakyReLU(self.l5_2(x),act_type='elu')\n",
    "            x = x.reshape((-1,8*8*3*self.num_channel))\n",
    "            x = self.l6(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrominator 형태\n",
    "- 기존 GAN의 경우에는 generator을 통해 생성된 이미지와 원래 이미지를 비교하는 형태임\n",
    "- BEGAN의 경우에는 Encoder -> Decoder 과정을 거쳐 생성된 이미지와 generator을 통해 생성된 이미지를 비교함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Block):\n",
    "    def __init__(self,param,**kwargs):\n",
    "        super(Discriminator,self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.enc = Encoder(param)\n",
    "            self.dec = Decoder(param)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##learning rate를 조절하기 위한 class\n",
    "class SimpleLRScheduler(lr_scheduler.LRScheduler):\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        super(SimpleLRScheduler, self).__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "    def __call__(self, num_update):\n",
    "        return self.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load image data\n",
    "lfw_url = 'http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz'\n",
    "data_path = 'lfw_dataset'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    data_file = utils.download(lfw_url)\n",
    "    with tarfile.open(data_file) as tar:\n",
    "        tar.extractall(path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict()\n",
    "param['num_channel'] = 64\n",
    "param['batch_size'] = 16\n",
    "param['image_size'] = 64\n",
    "#param['h'] = 64\n",
    "param['scale_size'] = 64\n",
    "param['latent_z_size'] = 8 * 8 * 3 * param['num_channel']\n",
    "param['k'] = 0\n",
    "param['gamma'] = 0.5\n",
    "param['lambda_k'] = 0.001\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_wd = 32\n",
    "target_ht = 32\n",
    "img_list = []\n",
    "\n",
    "def transform(data, target_wd, target_ht):\n",
    "    # resize to target_wd * target_ht\n",
    "    data = mx.image.imresize(data, target_wd, target_ht)\n",
    "    # transpose from (target_wd, target_ht, 3)\n",
    "    # to (3, target_wd, target_ht)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    # normalize to [-1, 1]\n",
    "    #data = data.astype(np.float32)/127.5 - 1\n",
    "    data = data.astype(np.float32)/255.0\n",
    "    # if image is greyscale, repeat 3 times to get RGB image.\n",
    "    if data.shape[0] == 1:\n",
    "        data = nd.tile(data, (3, 1, 1))\n",
    "    return data.reshape((1,) + data.shape)\n",
    "\n",
    "for path, _, fnames in os.walk(data_path):\n",
    "    for fname in fnames:\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "        img = os.path.join(path, fname)\n",
    "        img_arr = mx.image.imread(img)\n",
    "        img_arr = transform(img_arr, target_wd, target_ht)\n",
    "        img_list.append(img_arr)\n",
    "train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list), batch_size=param['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAABqCAYAAABK4WFIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa208304470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(img_arr):\n",
    "    #plt.imshow(((img_arr.asnumpy().transpose(1, 2, 0) + 1.0) * 127.5).astype(np.uint8))\n",
    "    plt.imshow(((img_arr.asnumpy().transpose(1, 2, 0)) * 255.0).astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    visualize(img_list[i+22][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define model\n",
    "disc = Discriminator(param)\n",
    "gen = Decoder(param)\n",
    "\n",
    "#parameter initialize\n",
    "disc.collect_params().initialize(mx.init.Normal(0.02),ctx=ctx)\n",
    "gen.collect_params().initialize(mx.init.Normal(0.02),ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##loss 설정\n",
    "- WGAN에서 사용한 방법을 적용\n",
    "- 일종의 autoencoder를 통해 산출된 결과와 input data와의 Wassersterian distance의 lower bound를 loss로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(outputs_d_x,data,outputs_d_z,gen_z):\n",
    "    real_loss_d = F.mean(F.abs(outputs_d_x - data))\n",
    "    fake_loss_d = F.mean(F.abs(outputs_d_z - gen_z))\n",
    "    return (real_loss_d,fake_loss_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loss(outputs_g_z,gen_z):\n",
    "    loss = F.mean(F.abs(outputs_g_z - gen_z))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define optimizer\n",
    "lr_scheduler = SimpleLRScheduler(learning_rate=0.0001)\n",
    "train_gen = gluon.Trainer(gen.collect_params(),optimizer='Adam',optimizer_params={'lr_scheduler':lr_scheduler,'beta1':0.5,'beta2':0.999})\n",
    "train_disc = gluon.Trainer(disc.collect_params(),optimizer='Adam',optimizer_params={'lr_scheduler':lr_scheduler,'beta1':0.5,'beta2':0.999})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loss = dict()\n",
    "iter_loss['lossD'] =[]\n",
    "iter_loss['lossG'] =[]\n",
    "iter_loss['k'] =[]\n",
    "iter_loss['conv_measure'] =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bound Equilibrium 적용\n",
    "\\begin{align}\n",
    "L_D = L(x) - k_tL(G(z_d)) ~~~~ for ~~\\theta_D  \\\\\n",
    "L_G = L(G(z_G)) ~~~~ for ~~\\theta_D  \\\\\n",
    "k_t+1 = k_t + \\lambda_k(\\gamma L(x) - L(G(z_G))) ~~~~ for~each~training~step~t\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.381832, generator loss = 0.000267, conv_measurec = 0.572719 at iteration 0\n",
      "discriminator loss = 0.141072, generator loss = 0.044411, conv_measurec = 0.176953 at iteration 200\n",
      "discriminator loss = 0.132325, generator loss = 0.057234, conv_measurec = 0.153947 at iteration 400\n",
      "discriminator loss = 0.139001, generator loss = 0.044392, conv_measurec = 0.166635 at iteration 600\n",
      "discriminator loss = 0.104097, generator loss = 0.035613, conv_measurec = 0.119056 at iteration 800\n",
      "discriminator loss = 0.102891, generator loss = 0.032194, conv_measurec = 0.114535 at iteration 1000\n",
      "discriminator loss = 0.133288, generator loss = 0.055198, conv_measurec = 0.162105 at iteration 1200\n",
      "discriminator loss = 0.103090, generator loss = 0.046646, conv_measurec = 0.117260 at iteration 1400\n",
      "discriminator loss = 0.095714, generator loss = 0.032125, conv_measurec = 0.111793 at iteration 1600\n",
      "discriminator loss = 0.084585, generator loss = 0.030847, conv_measurec = 0.089213 at iteration 1800\n",
      "discriminator loss = 0.090855, generator loss = 0.034078, conv_measurec = 0.101011 at iteration 2000\n",
      "discriminator loss = 0.088222, generator loss = 0.039966, conv_measurec = 0.103421 at iteration 2200\n",
      "discriminator loss = 0.087244, generator loss = 0.034753, conv_measurec = 0.092601 at iteration 2400\n",
      "discriminator loss = 0.089564, generator loss = 0.038537, conv_measurec = 0.094259 at iteration 2600\n",
      "discriminator loss = 0.083105, generator loss = 0.048811, conv_measurec = 0.092773 at iteration 2800\n",
      "discriminator loss = 0.068478, generator loss = 0.045064, conv_measurec = 0.074419 at iteration 3000\n",
      "discriminator loss = 0.087636, generator loss = 0.044916, conv_measurec = 0.091511 at iteration 3200\n",
      "discriminator loss = 0.076194, generator loss = 0.046755, conv_measurec = 0.078892 at iteration 3400\n",
      "discriminator loss = 0.087260, generator loss = 0.034492, conv_measurec = 0.101969 at iteration 3600\n",
      "discriminator loss = 0.085756, generator loss = 0.034905, conv_measurec = 0.094834 at iteration 3800\n",
      "discriminator loss = 0.076431, generator loss = 0.038746, conv_measurec = 0.079193 at iteration 4000\n",
      "discriminator loss = 0.083428, generator loss = 0.030164, conv_measurec = 0.098108 at iteration 4200\n",
      "discriminator loss = 0.077039, generator loss = 0.032009, conv_measurec = 0.086991 at iteration 4400\n",
      "discriminator loss = 0.089982, generator loss = 0.042327, conv_measurec = 0.097196 at iteration 4600\n",
      "discriminator loss = 0.078080, generator loss = 0.038893, conv_measurec = 0.085432 at iteration 4800\n",
      "discriminator loss = 0.079963, generator loss = 0.036885, conv_measurec = 0.091630 at iteration 5000\n",
      "discriminator loss = 0.070412, generator loss = 0.028654, conv_measurec = 0.079013 at iteration 5200\n",
      "discriminator loss = 0.058556, generator loss = 0.026271, conv_measurec = 0.064585 at iteration 5400\n",
      "discriminator loss = 0.074983, generator loss = 0.038168, conv_measurec = 0.079529 at iteration 5600\n",
      "discriminator loss = 0.073666, generator loss = 0.035829, conv_measurec = 0.080324 at iteration 5800\n",
      "discriminator loss = 0.071364, generator loss = 0.028981, conv_measurec = 0.078565 at iteration 6000\n",
      "discriminator loss = 0.068508, generator loss = 0.029773, conv_measurec = 0.077860 at iteration 6200\n",
      "discriminator loss = 0.082743, generator loss = 0.036591, conv_measurec = 0.096081 at iteration 6400\n",
      "discriminator loss = 0.079132, generator loss = 0.031964, conv_measurec = 0.091329 at iteration 6600\n",
      "discriminator loss = 0.071360, generator loss = 0.038833, conv_measurec = 0.076106 at iteration 6800\n",
      "discriminator loss = 0.072664, generator loss = 0.035470, conv_measurec = 0.079066 at iteration 7000\n",
      "discriminator loss = 0.067853, generator loss = 0.034657, conv_measurec = 0.074283 at iteration 7200\n",
      "discriminator loss = 0.079910, generator loss = 0.033050, conv_measurec = 0.084424 at iteration 7400\n",
      "discriminator loss = 0.071143, generator loss = 0.044178, conv_measurec = 0.074652 at iteration 7600\n",
      "discriminator loss = 0.066374, generator loss = 0.031739, conv_measurec = 0.072261 at iteration 7800\n",
      "discriminator loss = 0.059073, generator loss = 0.031384, conv_measurec = 0.069363 at iteration 8000\n",
      "discriminator loss = 0.062735, generator loss = 0.032066, conv_measurec = 0.072634 at iteration 8200\n",
      "discriminator loss = 0.065557, generator loss = 0.031144, conv_measurec = 0.069697 at iteration 8400\n",
      "discriminator loss = 0.057254, generator loss = 0.035827, conv_measurec = 0.062147 at iteration 8600\n",
      "discriminator loss = 0.060414, generator loss = 0.039335, conv_measurec = 0.063561 at iteration 8800\n",
      "discriminator loss = 0.065561, generator loss = 0.036289, conv_measurec = 0.068631 at iteration 9000\n",
      "discriminator loss = 0.059573, generator loss = 0.030380, conv_measurec = 0.064692 at iteration 9200\n",
      "discriminator loss = 0.057042, generator loss = 0.032394, conv_measurec = 0.063904 at iteration 9400\n",
      "discriminator loss = 0.051155, generator loss = 0.029555, conv_measurec = 0.056080 at iteration 9600\n",
      "discriminator loss = 0.050008, generator loss = 0.028587, conv_measurec = 0.058648 at iteration 9800\n",
      "discriminator loss = 0.058533, generator loss = 0.031594, conv_measurec = 0.060780 at iteration 10000\n",
      "discriminator loss = 0.062965, generator loss = 0.038347, conv_measurec = 0.067069 at iteration 10200\n",
      "discriminator loss = 0.056726, generator loss = 0.035759, conv_measurec = 0.065309 at iteration 10400\n",
      "discriminator loss = 0.055983, generator loss = 0.033757, conv_measurec = 0.061935 at iteration 10600\n",
      "discriminator loss = 0.053559, generator loss = 0.032678, conv_measurec = 0.057289 at iteration 10800\n",
      "discriminator loss = 0.061484, generator loss = 0.027457, conv_measurec = 0.064771 at iteration 11000\n",
      "discriminator loss = 0.050237, generator loss = 0.027972, conv_measurec = 0.054827 at iteration 11200\n",
      "discriminator loss = 0.057058, generator loss = 0.038160, conv_measurec = 0.064682 at iteration 11400\n",
      "discriminator loss = 0.053430, generator loss = 0.031427, conv_measurec = 0.062204 at iteration 11600\n",
      "discriminator loss = 0.067123, generator loss = 0.031014, conv_measurec = 0.074596 at iteration 11800\n",
      "discriminator loss = 0.054484, generator loss = 0.027945, conv_measurec = 0.058936 at iteration 12000\n",
      "discriminator loss = 0.065773, generator loss = 0.031056, conv_measurec = 0.073475 at iteration 12200\n",
      "discriminator loss = 0.055920, generator loss = 0.033225, conv_measurec = 0.059386 at iteration 12400\n",
      "discriminator loss = 0.063254, generator loss = 0.030690, conv_measurec = 0.067154 at iteration 12600\n",
      "discriminator loss = 0.048971, generator loss = 0.028794, conv_measurec = 0.055022 at iteration 12800\n",
      "discriminator loss = 0.053979, generator loss = 0.031480, conv_measurec = 0.060165 at iteration 13000\n",
      "discriminator loss = 0.047316, generator loss = 0.025923, conv_measurec = 0.053086 at iteration 13200\n",
      "discriminator loss = 0.056348, generator loss = 0.031186, conv_measurec = 0.058527 at iteration 13400\n",
      "discriminator loss = 0.074996, generator loss = 0.045033, conv_measurec = 0.078298 at iteration 13600\n",
      "discriminator loss = 0.059507, generator loss = 0.031437, conv_measurec = 0.062775 at iteration 13800\n",
      "discriminator loss = 0.048517, generator loss = 0.026666, conv_measurec = 0.050422 at iteration 14000\n",
      "discriminator loss = 0.052776, generator loss = 0.028970, conv_measurec = 0.055337 at iteration 14200\n",
      "discriminator loss = 0.047712, generator loss = 0.027078, conv_measurec = 0.050800 at iteration 14400\n",
      "discriminator loss = 0.058556, generator loss = 0.032542, conv_measurec = 0.061266 at iteration 14600\n",
      "discriminator loss = 0.060140, generator loss = 0.028537, conv_measurec = 0.062553 at iteration 14800\n",
      "discriminator loss = 0.055545, generator loss = 0.026292, conv_measurec = 0.059780 at iteration 15000\n",
      "discriminator loss = 0.051227, generator loss = 0.030488, conv_measurec = 0.054339 at iteration 15200\n",
      "discriminator loss = 0.053152, generator loss = 0.032501, conv_measurec = 0.057115 at iteration 15400\n",
      "discriminator loss = 0.055861, generator loss = 0.030066, conv_measurec = 0.058991 at iteration 15600\n",
      "discriminator loss = 0.053430, generator loss = 0.031126, conv_measurec = 0.055743 at iteration 15800\n",
      "discriminator loss = 0.051919, generator loss = 0.026101, conv_measurec = 0.055770 at iteration 16000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.053416, generator loss = 0.025761, conv_measurec = 0.056029 at iteration 16200\n",
      "discriminator loss = 0.050792, generator loss = 0.028091, conv_measurec = 0.054357 at iteration 16400\n",
      "discriminator loss = 0.052174, generator loss = 0.027766, conv_measurec = 0.056752 at iteration 16600\n",
      "discriminator loss = 0.043699, generator loss = 0.025169, conv_measurec = 0.047132 at iteration 16800\n",
      "discriminator loss = 0.047943, generator loss = 0.029749, conv_measurec = 0.053736 at iteration 17000\n",
      "discriminator loss = 0.047143, generator loss = 0.032998, conv_measurec = 0.056810 at iteration 17200\n",
      "discriminator loss = 0.052575, generator loss = 0.027001, conv_measurec = 0.055939 at iteration 17400\n",
      "discriminator loss = 0.053060, generator loss = 0.026617, conv_measurec = 0.055611 at iteration 17600\n",
      "discriminator loss = 0.049284, generator loss = 0.028026, conv_measurec = 0.051349 at iteration 17800\n",
      "discriminator loss = 0.056336, generator loss = 0.028291, conv_measurec = 0.060578 at iteration 18000\n",
      "discriminator loss = 0.050249, generator loss = 0.024409, conv_measurec = 0.053141 at iteration 18200\n",
      "discriminator loss = 0.058486, generator loss = 0.028058, conv_measurec = 0.063211 at iteration 18400\n",
      "discriminator loss = 0.055749, generator loss = 0.027115, conv_measurec = 0.057938 at iteration 18600\n",
      "discriminator loss = 0.052346, generator loss = 0.027746, conv_measurec = 0.055165 at iteration 18800\n",
      "discriminator loss = 0.043907, generator loss = 0.027021, conv_measurec = 0.050109 at iteration 19000\n",
      "discriminator loss = 0.049098, generator loss = 0.029902, conv_measurec = 0.053451 at iteration 19200\n",
      "discriminator loss = 0.046612, generator loss = 0.028920, conv_measurec = 0.052855 at iteration 19400\n",
      "discriminator loss = 0.051248, generator loss = 0.026566, conv_measurec = 0.053710 at iteration 19600\n",
      "discriminator loss = 0.051684, generator loss = 0.025522, conv_measurec = 0.055548 at iteration 19800\n",
      "discriminator loss = 0.048912, generator loss = 0.027909, conv_measurec = 0.052806 at iteration 20000\n",
      "discriminator loss = 0.048718, generator loss = 0.027436, conv_measurec = 0.050458 at iteration 20200\n",
      "discriminator loss = 0.056872, generator loss = 0.027522, conv_measurec = 0.060278 at iteration 20400\n",
      "discriminator loss = 0.053855, generator loss = 0.028616, conv_measurec = 0.056530 at iteration 20600\n",
      "discriminator loss = 0.046211, generator loss = 0.025432, conv_measurec = 0.050098 at iteration 20800\n",
      "discriminator loss = 0.042720, generator loss = 0.026744, conv_measurec = 0.049928 at iteration 21000\n",
      "discriminator loss = 0.055016, generator loss = 0.028510, conv_measurec = 0.059027 at iteration 21200\n",
      "discriminator loss = 0.052278, generator loss = 0.022879, conv_measurec = 0.058209 at iteration 21400\n",
      "discriminator loss = 0.055432, generator loss = 0.027396, conv_measurec = 0.059116 at iteration 21600\n",
      "discriminator loss = 0.052329, generator loss = 0.029004, conv_measurec = 0.054367 at iteration 21800\n",
      "discriminator loss = 0.047124, generator loss = 0.026437, conv_measurec = 0.049552 at iteration 22000\n",
      "discriminator loss = 0.048697, generator loss = 0.028102, conv_measurec = 0.051259 at iteration 22200\n",
      "discriminator loss = 0.043209, generator loss = 0.024724, conv_measurec = 0.046013 at iteration 22400\n",
      "discriminator loss = 0.045243, generator loss = 0.027677, conv_measurec = 0.049930 at iteration 22600\n",
      "discriminator loss = 0.060300, generator loss = 0.026803, conv_measurec = 0.066804 at iteration 22800\n",
      "discriminator loss = 0.045351, generator loss = 0.031007, conv_measurec = 0.056128 at iteration 23000\n",
      "discriminator loss = 0.046476, generator loss = 0.024025, conv_measurec = 0.048752 at iteration 23200\n",
      "discriminator loss = 0.048417, generator loss = 0.023882, conv_measurec = 0.051358 at iteration 23400\n",
      "discriminator loss = 0.050312, generator loss = 0.027920, conv_measurec = 0.054005 at iteration 23600\n",
      "discriminator loss = 0.054723, generator loss = 0.028031, conv_measurec = 0.056763 at iteration 23800\n",
      "discriminator loss = 0.049582, generator loss = 0.025226, conv_measurec = 0.052195 at iteration 24000\n",
      "discriminator loss = 0.053273, generator loss = 0.027418, conv_measurec = 0.055223 at iteration 24200\n",
      "discriminator loss = 0.047853, generator loss = 0.028026, conv_measurec = 0.053539 at iteration 24400\n",
      "discriminator loss = 0.049554, generator loss = 0.026331, conv_measurec = 0.051006 at iteration 24600\n",
      "discriminator loss = 0.050216, generator loss = 0.027171, conv_measurec = 0.052897 at iteration 24800\n",
      "discriminator loss = 0.050830, generator loss = 0.025983, conv_measurec = 0.052381 at iteration 25000\n",
      "discriminator loss = 0.054926, generator loss = 0.028337, conv_measurec = 0.057460 at iteration 25200\n",
      "discriminator loss = 0.042010, generator loss = 0.026460, conv_measurec = 0.047879 at iteration 25400\n",
      "discriminator loss = 0.043872, generator loss = 0.025811, conv_measurec = 0.048541 at iteration 25600\n",
      "discriminator loss = 0.047885, generator loss = 0.025338, conv_measurec = 0.050186 at iteration 25800\n",
      "discriminator loss = 0.055977, generator loss = 0.025295, conv_measurec = 0.061384 at iteration 26000\n",
      "discriminator loss = 0.052022, generator loss = 0.027313, conv_measurec = 0.054410 at iteration 26200\n",
      "discriminator loss = 0.048491, generator loss = 0.030876, conv_measurec = 0.054817 at iteration 26400\n",
      "discriminator loss = 0.041815, generator loss = 0.027376, conv_measurec = 0.048557 at iteration 26600\n",
      "discriminator loss = 0.047102, generator loss = 0.027791, conv_measurec = 0.052082 at iteration 26800\n",
      "discriminator loss = 0.048886, generator loss = 0.024650, conv_measurec = 0.050208 at iteration 27000\n",
      "discriminator loss = 0.048874, generator loss = 0.024345, conv_measurec = 0.050735 at iteration 27200\n",
      "discriminator loss = 0.057648, generator loss = 0.027128, conv_measurec = 0.061300 at iteration 27400\n",
      "discriminator loss = 0.043068, generator loss = 0.023486, conv_measurec = 0.046354 at iteration 27600\n",
      "discriminator loss = 0.042225, generator loss = 0.025901, conv_measurec = 0.047693 at iteration 27800\n",
      "discriminator loss = 0.044443, generator loss = 0.026165, conv_measurec = 0.049382 at iteration 28000\n",
      "discriminator loss = 0.053671, generator loss = 0.025308, conv_measurec = 0.056725 at iteration 28200\n",
      "discriminator loss = 0.056525, generator loss = 0.025968, conv_measurec = 0.061344 at iteration 28400\n",
      "discriminator loss = 0.040347, generator loss = 0.024775, conv_measurec = 0.046714 at iteration 28600\n",
      "discriminator loss = 0.049531, generator loss = 0.027796, conv_measurec = 0.052770 at iteration 28800\n",
      "discriminator loss = 0.048762, generator loss = 0.024187, conv_measurec = 0.051398 at iteration 29000\n",
      "discriminator loss = 0.043960, generator loss = 0.023248, conv_measurec = 0.046135 at iteration 29200\n",
      "discriminator loss = 0.054928, generator loss = 0.028362, conv_measurec = 0.056733 at iteration 29400\n",
      "discriminator loss = 0.045899, generator loss = 0.025702, conv_measurec = 0.049992 at iteration 29600\n",
      "discriminator loss = 0.044179, generator loss = 0.025859, conv_measurec = 0.048439 at iteration 29800\n",
      "discriminator loss = 0.057119, generator loss = 0.024423, conv_measurec = 0.062765 at iteration 30000\n",
      "discriminator loss = 0.044816, generator loss = 0.027024, conv_measurec = 0.050327 at iteration 30200\n",
      "discriminator loss = 0.045791, generator loss = 0.026144, conv_measurec = 0.050058 at iteration 30400\n",
      "discriminator loss = 0.046703, generator loss = 0.024437, conv_measurec = 0.047890 at iteration 30600\n",
      "discriminator loss = 0.042669, generator loss = 0.025337, conv_measurec = 0.047778 at iteration 30800\n",
      "discriminator loss = 0.041513, generator loss = 0.027663, conv_measurec = 0.048901 at iteration 31000\n",
      "discriminator loss = 0.045667, generator loss = 0.025139, conv_measurec = 0.048823 at iteration 31200\n",
      "discriminator loss = 0.044083, generator loss = 0.023945, conv_measurec = 0.046302 at iteration 31400\n",
      "discriminator loss = 0.051420, generator loss = 0.027160, conv_measurec = 0.052750 at iteration 31600\n",
      "discriminator loss = 0.040404, generator loss = 0.023898, conv_measurec = 0.044958 at iteration 31800\n",
      "discriminator loss = 0.048533, generator loss = 0.026655, conv_measurec = 0.051543 at iteration 32000\n",
      "discriminator loss = 0.042611, generator loss = 0.026759, conv_measurec = 0.048047 at iteration 32200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.044688, generator loss = 0.023996, conv_measurec = 0.047260 at iteration 32400\n",
      "discriminator loss = 0.048870, generator loss = 0.026539, conv_measurec = 0.051635 at iteration 32600\n",
      "discriminator loss = 0.043601, generator loss = 0.026493, conv_measurec = 0.048832 at iteration 32800\n",
      "discriminator loss = 0.052452, generator loss = 0.024101, conv_measurec = 0.056075 at iteration 33000\n",
      "discriminator loss = 0.041176, generator loss = 0.025323, conv_measurec = 0.046406 at iteration 33200\n",
      "discriminator loss = 0.040681, generator loss = 0.025490, conv_measurec = 0.046015 at iteration 33400\n",
      "discriminator loss = 0.047689, generator loss = 0.025386, conv_measurec = 0.049649 at iteration 33600\n",
      "discriminator loss = 0.047269, generator loss = 0.025586, conv_measurec = 0.049453 at iteration 33800\n",
      "discriminator loss = 0.044775, generator loss = 0.024189, conv_measurec = 0.046980 at iteration 34000\n",
      "discriminator loss = 0.043483, generator loss = 0.023920, conv_measurec = 0.046529 at iteration 34200\n",
      "discriminator loss = 0.039736, generator loss = 0.023704, conv_measurec = 0.043412 at iteration 34400\n",
      "discriminator loss = 0.044861, generator loss = 0.026727, conv_measurec = 0.050188 at iteration 34600\n",
      "discriminator loss = 0.048918, generator loss = 0.025862, conv_measurec = 0.050265 at iteration 34800\n",
      "discriminator loss = 0.050052, generator loss = 0.026579, conv_measurec = 0.051830 at iteration 35000\n",
      "discriminator loss = 0.047603, generator loss = 0.025890, conv_measurec = 0.050508 at iteration 35200\n",
      "discriminator loss = 0.050962, generator loss = 0.024675, conv_measurec = 0.053062 at iteration 35400\n",
      "discriminator loss = 0.041277, generator loss = 0.024269, conv_measurec = 0.045423 at iteration 35600\n",
      "discriminator loss = 0.046951, generator loss = 0.025993, conv_measurec = 0.049606 at iteration 35800\n",
      "discriminator loss = 0.042396, generator loss = 0.025434, conv_measurec = 0.047250 at iteration 36000\n",
      "discriminator loss = 0.045479, generator loss = 0.025416, conv_measurec = 0.048788 at iteration 36200\n",
      "discriminator loss = 0.042971, generator loss = 0.025533, conv_measurec = 0.047530 at iteration 36400\n",
      "discriminator loss = 0.044723, generator loss = 0.025154, conv_measurec = 0.048046 at iteration 36600\n",
      "discriminator loss = 0.045998, generator loss = 0.025466, conv_measurec = 0.048925 at iteration 36800\n",
      "discriminator loss = 0.042883, generator loss = 0.024585, conv_measurec = 0.046344 at iteration 37000\n",
      "discriminator loss = 0.049354, generator loss = 0.024634, conv_measurec = 0.050796 at iteration 37200\n",
      "discriminator loss = 0.047179, generator loss = 0.025140, conv_measurec = 0.049214 at iteration 37400\n",
      "discriminator loss = 0.043491, generator loss = 0.023846, conv_measurec = 0.045931 at iteration 37600\n",
      "discriminator loss = 0.052807, generator loss = 0.025192, conv_measurec = 0.055381 at iteration 37800\n",
      "discriminator loss = 0.049457, generator loss = 0.024192, conv_measurec = 0.051018 at iteration 38000\n",
      "discriminator loss = 0.045979, generator loss = 0.024156, conv_measurec = 0.047518 at iteration 38200\n",
      "discriminator loss = 0.038969, generator loss = 0.024522, conv_measurec = 0.044445 at iteration 38400\n",
      "discriminator loss = 0.038436, generator loss = 0.025858, conv_measurec = 0.045605 at iteration 38600\n",
      "discriminator loss = 0.049172, generator loss = 0.024479, conv_measurec = 0.050612 at iteration 38800\n",
      "discriminator loss = 0.047537, generator loss = 0.025601, conv_measurec = 0.049620 at iteration 39000\n",
      "discriminator loss = 0.046455, generator loss = 0.025094, conv_measurec = 0.048678 at iteration 39200\n",
      "discriminator loss = 0.042764, generator loss = 0.023840, conv_measurec = 0.045628 at iteration 39400\n",
      "discriminator loss = 0.045371, generator loss = 0.024476, conv_measurec = 0.047537 at iteration 39600\n",
      "discriminator loss = 0.045935, generator loss = 0.024652, conv_measurec = 0.047929 at iteration 39800\n",
      "discriminator loss = 0.049265, generator loss = 0.023741, conv_measurec = 0.051258 at iteration 40000\n",
      "discriminator loss = 0.045671, generator loss = 0.022057, conv_measurec = 0.047499 at iteration 40200\n",
      "discriminator loss = 0.048864, generator loss = 0.024522, conv_measurec = 0.049954 at iteration 40400\n",
      "discriminator loss = 0.047900, generator loss = 0.023756, conv_measurec = 0.049143 at iteration 40600\n",
      "discriminator loss = 0.056205, generator loss = 0.025400, conv_measurec = 0.060121 at iteration 40800\n",
      "discriminator loss = 0.044619, generator loss = 0.023162, conv_measurec = 0.045848 at iteration 41000\n",
      "discriminator loss = 0.044415, generator loss = 0.023973, conv_measurec = 0.046509 at iteration 41200\n",
      "discriminator loss = 0.046587, generator loss = 0.022748, conv_measurec = 0.048320 at iteration 41400\n",
      "discriminator loss = 0.047147, generator loss = 0.024090, conv_measurec = 0.048031 at iteration 41600\n",
      "discriminator loss = 0.046471, generator loss = 0.024439, conv_measurec = 0.048035 at iteration 41800\n",
      "discriminator loss = 0.060554, generator loss = 0.024099, conv_measurec = 0.067780 at iteration 42000\n",
      "discriminator loss = 0.044603, generator loss = 0.024256, conv_measurec = 0.047011 at iteration 42200\n",
      "discriminator loss = 0.042524, generator loss = 0.024575, conv_measurec = 0.046285 at iteration 42400\n",
      "discriminator loss = 0.053240, generator loss = 0.024787, conv_measurec = 0.056224 at iteration 42600\n",
      "discriminator loss = 0.044690, generator loss = 0.023803, conv_measurec = 0.046532 at iteration 42800\n",
      "discriminator loss = 0.041777, generator loss = 0.023679, conv_measurec = 0.044936 at iteration 43000\n",
      "discriminator loss = 0.040071, generator loss = 0.025339, conv_measurec = 0.045823 at iteration 43200\n",
      "discriminator loss = 0.043498, generator loss = 0.024728, conv_measurec = 0.046828 at iteration 43400\n",
      "discriminator loss = 0.045428, generator loss = 0.024357, conv_measurec = 0.047465 at iteration 43600\n",
      "discriminator loss = 0.044271, generator loss = 0.023655, conv_measurec = 0.046149 at iteration 43800\n",
      "discriminator loss = 0.045593, generator loss = 0.024918, conv_measurec = 0.047980 at iteration 44000\n",
      "discriminator loss = 0.043902, generator loss = 0.023225, conv_measurec = 0.045534 at iteration 44200\n",
      "discriminator loss = 0.035189, generator loss = 0.024541, conv_measurec = 0.042468 at iteration 44400\n",
      "discriminator loss = 0.052895, generator loss = 0.024909, conv_measurec = 0.055490 at iteration 44600\n",
      "discriminator loss = 0.042458, generator loss = 0.024877, conv_measurec = 0.046412 at iteration 44800\n",
      "discriminator loss = 0.045059, generator loss = 0.023217, conv_measurec = 0.046054 at iteration 45000\n",
      "discriminator loss = 0.047025, generator loss = 0.023673, conv_measurec = 0.047863 at iteration 45200\n",
      "discriminator loss = 0.047059, generator loss = 0.025279, conv_measurec = 0.049163 at iteration 45400\n",
      "discriminator loss = 0.049458, generator loss = 0.024130, conv_measurec = 0.051069 at iteration 45600\n",
      "discriminator loss = 0.045046, generator loss = 0.022881, conv_measurec = 0.045722 at iteration 45800\n",
      "discriminator loss = 0.048496, generator loss = 0.023495, conv_measurec = 0.050226 at iteration 46000\n",
      "discriminator loss = 0.046351, generator loss = 0.024362, conv_measurec = 0.047875 at iteration 46200\n",
      "discriminator loss = 0.047932, generator loss = 0.022757, conv_measurec = 0.050083 at iteration 46400\n",
      "discriminator loss = 0.043402, generator loss = 0.023703, conv_measurec = 0.045709 at iteration 46600\n",
      "discriminator loss = 0.038142, generator loss = 0.023007, conv_measurec = 0.042452 at iteration 46800\n",
      "discriminator loss = 0.047623, generator loss = 0.024218, conv_measurec = 0.048364 at iteration 47000\n",
      "discriminator loss = 0.043914, generator loss = 0.023162, conv_measurec = 0.045438 at iteration 47200\n",
      "discriminator loss = 0.045471, generator loss = 0.024290, conv_measurec = 0.047351 at iteration 47400\n",
      "discriminator loss = 0.045929, generator loss = 0.023474, conv_measurec = 0.046752 at iteration 47600\n",
      "discriminator loss = 0.051859, generator loss = 0.024141, conv_measurec = 0.054636 at iteration 47800\n",
      "discriminator loss = 0.047358, generator loss = 0.024224, conv_measurec = 0.048194 at iteration 48000\n",
      "discriminator loss = 0.042182, generator loss = 0.024093, conv_measurec = 0.045505 at iteration 48200\n",
      "discriminator loss = 0.049793, generator loss = 0.024492, conv_measurec = 0.051200 at iteration 48400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.043568, generator loss = 0.024270, conv_measurec = 0.046376 at iteration 48600\n",
      "discriminator loss = 0.049521, generator loss = 0.024510, conv_measurec = 0.050745 at iteration 48800\n",
      "discriminator loss = 0.048581, generator loss = 0.023779, conv_measurec = 0.050031 at iteration 49000\n",
      "discriminator loss = 0.046275, generator loss = 0.023466, conv_measurec = 0.046910 at iteration 49200\n",
      "discriminator loss = 0.041334, generator loss = 0.025234, conv_measurec = 0.046226 at iteration 49400\n",
      "discriminator loss = 0.045752, generator loss = 0.024135, conv_measurec = 0.047315 at iteration 49600\n",
      "discriminator loss = 0.048612, generator loss = 0.024638, conv_measurec = 0.049251 at iteration 49800\n",
      "discriminator loss = 0.043502, generator loss = 0.023400, conv_measurec = 0.045454 at iteration 50000\n",
      "discriminator loss = 0.040827, generator loss = 0.024714, conv_measurec = 0.045445 at iteration 50200\n",
      "discriminator loss = 0.048521, generator loss = 0.024640, conv_measurec = 0.049203 at iteration 50400\n",
      "discriminator loss = 0.045753, generator loss = 0.024187, conv_measurec = 0.047369 at iteration 50600\n",
      "discriminator loss = 0.043658, generator loss = 0.025327, conv_measurec = 0.047454 at iteration 50800\n",
      "discriminator loss = 0.036639, generator loss = 0.023774, conv_measurec = 0.042386 at iteration 51000\n",
      "discriminator loss = 0.038406, generator loss = 0.024676, conv_measurec = 0.044184 at iteration 51200\n",
      "discriminator loss = 0.045528, generator loss = 0.025420, conv_measurec = 0.048493 at iteration 51400\n",
      "discriminator loss = 0.049234, generator loss = 0.025048, conv_measurec = 0.049964 at iteration 51600\n",
      "discriminator loss = 0.045885, generator loss = 0.024914, conv_measurec = 0.048152 at iteration 51800\n",
      "discriminator loss = 0.044239, generator loss = 0.025105, conv_measurec = 0.047520 at iteration 52000\n",
      "discriminator loss = 0.043106, generator loss = 0.024806, conv_measurec = 0.046649 at iteration 52200\n",
      "discriminator loss = 0.050044, generator loss = 0.023366, conv_measurec = 0.052516 at iteration 52400\n",
      "discriminator loss = 0.040072, generator loss = 0.024155, conv_measurec = 0.044474 at iteration 52600\n",
      "discriminator loss = 0.046381, generator loss = 0.024968, conv_measurec = 0.048443 at iteration 52800\n",
      "discriminator loss = 0.042875, generator loss = 0.023993, conv_measurec = 0.045700 at iteration 53000\n",
      "discriminator loss = 0.054943, generator loss = 0.025190, conv_measurec = 0.058078 at iteration 53200\n",
      "discriminator loss = 0.042927, generator loss = 0.023863, conv_measurec = 0.045592 at iteration 53400\n",
      "discriminator loss = 0.056748, generator loss = 0.024976, conv_measurec = 0.060971 at iteration 53600\n",
      "discriminator loss = 0.046398, generator loss = 0.024961, conv_measurec = 0.048429 at iteration 53800\n",
      "discriminator loss = 0.051936, generator loss = 0.025293, conv_measurec = 0.053433 at iteration 54000\n",
      "discriminator loss = 0.041163, generator loss = 0.025397, conv_measurec = 0.046251 at iteration 54200\n",
      "discriminator loss = 0.045839, generator loss = 0.024805, conv_measurec = 0.047987 at iteration 54400\n",
      "discriminator loss = 0.040002, generator loss = 0.024691, conv_measurec = 0.044951 at iteration 54600\n",
      "discriminator loss = 0.047454, generator loss = 0.025382, conv_measurec = 0.049374 at iteration 54800\n",
      "discriminator loss = 0.052605, generator loss = 0.024479, conv_measurec = 0.055188 at iteration 55000\n",
      "discriminator loss = 0.050395, generator loss = 0.024396, conv_measurec = 0.051945 at iteration 55200\n",
      "discriminator loss = 0.041913, generator loss = 0.024633, conv_measurec = 0.045842 at iteration 55400\n",
      "discriminator loss = 0.046019, generator loss = 0.025665, conv_measurec = 0.048933 at iteration 55600\n",
      "discriminator loss = 0.041308, generator loss = 0.024613, conv_measurec = 0.045515 at iteration 55800\n",
      "discriminator loss = 0.049475, generator loss = 0.024708, conv_measurec = 0.050234 at iteration 56000\n",
      "discriminator loss = 0.052628, generator loss = 0.024919, conv_measurec = 0.054753 at iteration 56200\n",
      "discriminator loss = 0.049264, generator loss = 0.024961, conv_measurec = 0.049832 at iteration 56400\n",
      "discriminator loss = 0.046114, generator loss = 0.024684, conv_measurec = 0.047976 at iteration 56600\n",
      "discriminator loss = 0.046563, generator loss = 0.024427, conv_measurec = 0.047939 at iteration 56800\n",
      "discriminator loss = 0.049841, generator loss = 0.024407, conv_measurec = 0.051040 at iteration 57000\n",
      "discriminator loss = 0.047175, generator loss = 0.024298, conv_measurec = 0.048111 at iteration 57200\n",
      "discriminator loss = 0.045925, generator loss = 0.024401, conv_measurec = 0.047588 at iteration 57400\n",
      "discriminator loss = 0.046962, generator loss = 0.023639, conv_measurec = 0.047448 at iteration 57600\n",
      "discriminator loss = 0.045413, generator loss = 0.025514, conv_measurec = 0.048451 at iteration 57800\n",
      "discriminator loss = 0.046961, generator loss = 0.024522, conv_measurec = 0.048222 at iteration 58000\n",
      "discriminator loss = 0.039103, generator loss = 0.024866, conv_measurec = 0.044638 at iteration 58200\n",
      "discriminator loss = 0.043450, generator loss = 0.024810, conv_measurec = 0.046753 at iteration 58400\n",
      "discriminator loss = 0.040577, generator loss = 0.023746, conv_measurec = 0.044240 at iteration 58600\n",
      "discriminator loss = 0.047936, generator loss = 0.023713, conv_measurec = 0.048802 at iteration 58800\n",
      "discriminator loss = 0.047922, generator loss = 0.024726, conv_measurec = 0.048900 at iteration 59000\n",
      "discriminator loss = 0.044930, generator loss = 0.023955, conv_measurec = 0.046623 at iteration 59200\n",
      "discriminator loss = 0.051258, generator loss = 0.024316, conv_measurec = 0.053181 at iteration 59400\n",
      "discriminator loss = 0.045271, generator loss = 0.025422, conv_measurec = 0.048268 at iteration 59600\n",
      "discriminator loss = 0.053799, generator loss = 0.023953, conv_measurec = 0.057336 at iteration 59800\n",
      "discriminator loss = 0.050164, generator loss = 0.024317, conv_measurec = 0.051522 at iteration 60000\n",
      "discriminator loss = 0.047957, generator loss = 0.024569, conv_measurec = 0.048744 at iteration 60200\n",
      "discriminator loss = 0.040039, generator loss = 0.024832, conv_measurec = 0.045050 at iteration 60400\n",
      "discriminator loss = 0.045717, generator loss = 0.024603, conv_measurec = 0.047656 at iteration 60600\n",
      "discriminator loss = 0.043241, generator loss = 0.023801, conv_measurec = 0.045608 at iteration 60800\n",
      "discriminator loss = 0.046886, generator loss = 0.024543, conv_measurec = 0.048176 at iteration 61000\n",
      "discriminator loss = 0.048230, generator loss = 0.024565, conv_measurec = 0.048868 at iteration 61200\n",
      "discriminator loss = 0.045719, generator loss = 0.025194, conv_measurec = 0.048244 at iteration 61400\n",
      "discriminator loss = 0.046014, generator loss = 0.025350, conv_measurec = 0.048548 at iteration 61600\n",
      "discriminator loss = 0.052390, generator loss = 0.024055, conv_measurec = 0.055066 at iteration 61800\n",
      "discriminator loss = 0.050805, generator loss = 0.024496, conv_measurec = 0.052255 at iteration 62000\n",
      "discriminator loss = 0.043740, generator loss = 0.024277, conv_measurec = 0.046325 at iteration 62200\n",
      "discriminator loss = 0.040297, generator loss = 0.024489, conv_measurec = 0.044814 at iteration 62400\n",
      "discriminator loss = 0.050696, generator loss = 0.024606, conv_measurec = 0.051966 at iteration 62600\n",
      "discriminator loss = 0.049657, generator loss = 0.024768, conv_measurec = 0.050244 at iteration 62800\n",
      "discriminator loss = 0.052233, generator loss = 0.026037, conv_measurec = 0.052862 at iteration 63000\n",
      "discriminator loss = 0.049861, generator loss = 0.023893, conv_measurec = 0.051400 at iteration 63200\n",
      "discriminator loss = 0.044814, generator loss = 0.023225, conv_measurec = 0.045792 at iteration 63400\n",
      "discriminator loss = 0.046804, generator loss = 0.024481, conv_measurec = 0.048050 at iteration 63600\n",
      "discriminator loss = 0.041617, generator loss = 0.024607, conv_measurec = 0.045581 at iteration 63800\n",
      "discriminator loss = 0.043002, generator loss = 0.025274, conv_measurec = 0.046945 at iteration 64000\n",
      "discriminator loss = 0.057164, generator loss = 0.024188, conv_measurec = 0.062038 at iteration 64200\n",
      "discriminator loss = 0.041484, generator loss = 0.024148, conv_measurec = 0.045048 at iteration 64400\n",
      "discriminator loss = 0.044492, generator loss = 0.023757, conv_measurec = 0.046157 at iteration 64600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.046186, generator loss = 0.023047, conv_measurec = 0.046677 at iteration 64800\n",
      "discriminator loss = 0.048184, generator loss = 0.024515, conv_measurec = 0.048762 at iteration 65000\n",
      "discriminator loss = 0.052906, generator loss = 0.024797, conv_measurec = 0.055029 at iteration 65200\n",
      "discriminator loss = 0.047768, generator loss = 0.024708, conv_measurec = 0.048745 at iteration 65400\n",
      "discriminator loss = 0.050709, generator loss = 0.023503, conv_measurec = 0.052996 at iteration 65600\n",
      "discriminator loss = 0.046169, generator loss = 0.025010, conv_measurec = 0.048247 at iteration 65800\n",
      "discriminator loss = 0.047107, generator loss = 0.024338, conv_measurec = 0.048037 at iteration 66000\n",
      "discriminator loss = 0.048198, generator loss = 0.024298, conv_measurec = 0.048542 at iteration 66200\n",
      "discriminator loss = 0.049350, generator loss = 0.024329, conv_measurec = 0.050126 at iteration 66400\n",
      "discriminator loss = 0.054045, generator loss = 0.023994, conv_measurec = 0.057492 at iteration 66600\n",
      "discriminator loss = 0.041023, generator loss = 0.024046, conv_measurec = 0.044696 at iteration 66800\n",
      "discriminator loss = 0.043091, generator loss = 0.023842, conv_measurec = 0.045523 at iteration 67000\n",
      "discriminator loss = 0.046301, generator loss = 0.024735, conv_measurec = 0.048024 at iteration 67200\n",
      "discriminator loss = 0.054703, generator loss = 0.024120, conv_measurec = 0.058336 at iteration 67400\n",
      "discriminator loss = 0.051088, generator loss = 0.024084, conv_measurec = 0.052943 at iteration 67600\n",
      "discriminator loss = 0.047387, generator loss = 0.024541, conv_measurec = 0.048368 at iteration 67800\n",
      "discriminator loss = 0.041269, generator loss = 0.025156, conv_measurec = 0.045925 at iteration 68000\n",
      "discriminator loss = 0.046532, generator loss = 0.023563, conv_measurec = 0.046954 at iteration 68200\n",
      "discriminator loss = 0.048035, generator loss = 0.024544, conv_measurec = 0.048690 at iteration 68400\n",
      "discriminator loss = 0.048014, generator loss = 0.024984, conv_measurec = 0.049119 at iteration 68600\n",
      "discriminator loss = 0.056723, generator loss = 0.022719, conv_measurec = 0.062712 at iteration 68800\n",
      "discriminator loss = 0.042450, generator loss = 0.024067, conv_measurec = 0.045414 at iteration 69000\n",
      "discriminator loss = 0.041908, generator loss = 0.023973, conv_measurec = 0.045045 at iteration 69200\n",
      "discriminator loss = 0.044265, generator loss = 0.024201, conv_measurec = 0.046452 at iteration 69400\n",
      "discriminator loss = 0.053213, generator loss = 0.024634, conv_measurec = 0.055543 at iteration 69600\n",
      "discriminator loss = 0.056072, generator loss = 0.024720, conv_measurec = 0.059744 at iteration 69800\n",
      "discriminator loss = 0.039899, generator loss = 0.024482, conv_measurec = 0.044546 at iteration 70000\n",
      "discriminator loss = 0.049069, generator loss = 0.023928, conv_measurec = 0.050009 at iteration 70200\n",
      "discriminator loss = 0.048393, generator loss = 0.024697, conv_measurec = 0.049006 at iteration 70400\n",
      "discriminator loss = 0.043637, generator loss = 0.023999, conv_measurec = 0.045926 at iteration 70600\n",
      "discriminator loss = 0.054736, generator loss = 0.023983, conv_measurec = 0.058440 at iteration 70800\n",
      "discriminator loss = 0.045411, generator loss = 0.024307, conv_measurec = 0.047119 at iteration 71000\n",
      "discriminator loss = 0.044082, generator loss = 0.024418, conv_measurec = 0.046564 at iteration 71200\n",
      "discriminator loss = 0.056826, generator loss = 0.024482, conv_measurec = 0.061068 at iteration 71400\n",
      "discriminator loss = 0.044571, generator loss = 0.024690, conv_measurec = 0.047078 at iteration 71600\n",
      "discriminator loss = 0.045602, generator loss = 0.023548, conv_measurec = 0.046445 at iteration 71800\n",
      "discriminator loss = 0.046859, generator loss = 0.024848, conv_measurec = 0.048377 at iteration 72000\n",
      "discriminator loss = 0.042697, generator loss = 0.024007, conv_measurec = 0.045451 at iteration 72200\n",
      "discriminator loss = 0.041701, generator loss = 0.024548, conv_measurec = 0.045494 at iteration 72400\n",
      "discriminator loss = 0.045831, generator loss = 0.023776, conv_measurec = 0.046782 at iteration 72600\n",
      "discriminator loss = 0.044176, generator loss = 0.024348, conv_measurec = 0.046527 at iteration 72800\n",
      "discriminator loss = 0.051608, generator loss = 0.023846, conv_measurec = 0.053831 at iteration 73000\n",
      "discriminator loss = 0.040534, generator loss = 0.024375, conv_measurec = 0.044730 at iteration 73200\n",
      "discriminator loss = 0.048535, generator loss = 0.024337, conv_measurec = 0.048723 at iteration 73400\n",
      "discriminator loss = 0.042806, generator loss = 0.023881, conv_measurec = 0.045367 at iteration 73600\n",
      "discriminator loss = 0.044874, generator loss = 0.024285, conv_measurec = 0.046805 at iteration 73800\n",
      "discriminator loss = 0.048976, generator loss = 0.023399, conv_measurec = 0.050300 at iteration 74000\n",
      "discriminator loss = 0.043766, generator loss = 0.024343, conv_measurec = 0.046306 at iteration 74200\n",
      "discriminator loss = 0.052569, generator loss = 0.023745, conv_measurec = 0.055338 at iteration 74400\n",
      "discriminator loss = 0.041489, generator loss = 0.024504, conv_measurec = 0.045326 at iteration 74600\n",
      "discriminator loss = 0.041035, generator loss = 0.024391, conv_measurec = 0.044984 at iteration 74800\n",
      "discriminator loss = 0.047989, generator loss = 0.025350, conv_measurec = 0.049421 at iteration 75000\n",
      "discriminator loss = 0.047773, generator loss = 0.024568, conv_measurec = 0.048527 at iteration 75200\n",
      "discriminator loss = 0.045114, generator loss = 0.024376, conv_measurec = 0.047004 at iteration 75400\n",
      "discriminator loss = 0.043788, generator loss = 0.025732, conv_measurec = 0.047699 at iteration 75600\n",
      "discriminator loss = 0.040104, generator loss = 0.023455, conv_measurec = 0.043572 at iteration 75800\n",
      "discriminator loss = 0.045194, generator loss = 0.024808, conv_measurec = 0.047471 at iteration 76000\n",
      "discriminator loss = 0.049255, generator loss = 0.024236, conv_measurec = 0.049837 at iteration 76200\n",
      "discriminator loss = 0.050455, generator loss = 0.024642, conv_measurec = 0.051231 at iteration 76400\n",
      "discriminator loss = 0.047978, generator loss = 0.023864, conv_measurec = 0.048281 at iteration 76600\n",
      "discriminator loss = 0.051471, generator loss = 0.024582, conv_measurec = 0.052803 at iteration 76800\n",
      "discriminator loss = 0.041747, generator loss = 0.023532, conv_measurec = 0.044461 at iteration 77000\n",
      "discriminator loss = 0.047185, generator loss = 0.024342, conv_measurec = 0.047991 at iteration 77200\n",
      "discriminator loss = 0.042803, generator loss = 0.024325, conv_measurec = 0.045781 at iteration 77400\n",
      "discriminator loss = 0.045972, generator loss = 0.022983, conv_measurec = 0.046123 at iteration 77600\n",
      "discriminator loss = 0.043501, generator loss = 0.024452, conv_measurec = 0.046253 at iteration 77800\n",
      "discriminator loss = 0.045289, generator loss = 0.023506, conv_measurec = 0.046198 at iteration 78000\n",
      "discriminator loss = 0.046615, generator loss = 0.023969, conv_measurec = 0.047323 at iteration 78200\n",
      "discriminator loss = 0.043336, generator loss = 0.023789, conv_measurec = 0.045502 at iteration 78400\n",
      "discriminator loss = 0.049971, generator loss = 0.024640, conv_measurec = 0.050451 at iteration 78600\n",
      "discriminator loss = 0.047797, generator loss = 0.023825, conv_measurec = 0.047997 at iteration 78800\n",
      "discriminator loss = 0.044049, generator loss = 0.023947, conv_measurec = 0.046012 at iteration 79000\n",
      "discriminator loss = 0.053338, generator loss = 0.024015, conv_measurec = 0.056108 at iteration 79200\n",
      "discriminator loss = 0.049845, generator loss = 0.025145, conv_measurec = 0.050107 at iteration 79400\n",
      "discriminator loss = 0.046471, generator loss = 0.023936, conv_measurec = 0.047206 at iteration 79600\n",
      "discriminator loss = 0.039375, generator loss = 0.024299, conv_measurec = 0.044021 at iteration 79800\n",
      "discriminator loss = 0.038959, generator loss = 0.024270, conv_measurec = 0.043782 at iteration 80000\n",
      "discriminator loss = 0.049816, generator loss = 0.024073, conv_measurec = 0.050745 at iteration 80200\n",
      "discriminator loss = 0.047996, generator loss = 0.024235, conv_measurec = 0.048263 at iteration 80400\n",
      "discriminator loss = 0.047112, generator loss = 0.023544, conv_measurec = 0.047209 at iteration 80600\n",
      "discriminator loss = 0.043317, generator loss = 0.024190, conv_measurec = 0.045875 at iteration 80800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.046035, generator loss = 0.024922, conv_measurec = 0.047965 at iteration 81000\n",
      "discriminator loss = 0.046660, generator loss = 0.025227, conv_measurec = 0.048581 at iteration 81200\n",
      "discriminator loss = 0.049950, generator loss = 0.023918, conv_measurec = 0.051071 at iteration 81400\n",
      "discriminator loss = 0.046206, generator loss = 0.025668, conv_measurec = 0.048792 at iteration 81600\n",
      "discriminator loss = 0.049508, generator loss = 0.024355, conv_measurec = 0.049961 at iteration 81800\n",
      "discriminator loss = 0.048567, generator loss = 0.024815, conv_measurec = 0.049116 at iteration 82000\n",
      "discriminator loss = 0.056801, generator loss = 0.024608, conv_measurec = 0.060640 at iteration 82200\n",
      "discriminator loss = 0.045145, generator loss = 0.023939, conv_measurec = 0.046524 at iteration 82400\n",
      "discriminator loss = 0.044936, generator loss = 0.024224, conv_measurec = 0.046704 at iteration 82600\n",
      "discriminator loss = 0.047252, generator loss = 0.024650, conv_measurec = 0.048287 at iteration 82800\n",
      "discriminator loss = 0.047761, generator loss = 0.023039, conv_measurec = 0.048628 at iteration 83000\n",
      "discriminator loss = 0.047113, generator loss = 0.023590, conv_measurec = 0.047154 at iteration 83200\n",
      "discriminator loss = 0.061217, generator loss = 0.024063, conv_measurec = 0.067777 at iteration 83400\n",
      "discriminator loss = 0.045209, generator loss = 0.023709, conv_measurec = 0.046317 at iteration 83600\n",
      "discriminator loss = 0.043138, generator loss = 0.024127, conv_measurec = 0.045698 at iteration 83800\n",
      "discriminator loss = 0.053892, generator loss = 0.024470, conv_measurec = 0.056369 at iteration 84000\n",
      "discriminator loss = 0.045328, generator loss = 0.024228, conv_measurec = 0.046890 at iteration 84200\n",
      "discriminator loss = 0.042374, generator loss = 0.023877, conv_measurec = 0.045061 at iteration 84400\n",
      "discriminator loss = 0.040778, generator loss = 0.024691, conv_measurec = 0.045076 at iteration 84600\n",
      "discriminator loss = 0.044214, generator loss = 0.023841, conv_measurec = 0.045942 at iteration 84800\n",
      "discriminator loss = 0.046055, generator loss = 0.024804, conv_measurec = 0.047823 at iteration 85000\n",
      "discriminator loss = 0.044957, generator loss = 0.023753, conv_measurec = 0.046222 at iteration 85200\n",
      "discriminator loss = 0.046283, generator loss = 0.023806, conv_measurec = 0.046937 at iteration 85400\n",
      "discriminator loss = 0.044559, generator loss = 0.024253, conv_measurec = 0.046520 at iteration 85600\n",
      "discriminator loss = 0.035846, generator loss = 0.024863, conv_measurec = 0.042771 at iteration 85800\n",
      "discriminator loss = 0.053550, generator loss = 0.024202, conv_measurec = 0.056075 at iteration 86000\n",
      "discriminator loss = 0.043152, generator loss = 0.023929, conv_measurec = 0.045488 at iteration 86200\n",
      "discriminator loss = 0.045715, generator loss = 0.024213, conv_measurec = 0.047052 at iteration 86400\n",
      "discriminator loss = 0.047677, generator loss = 0.024800, conv_measurec = 0.048617 at iteration 86600\n",
      "discriminator loss = 0.047670, generator loss = 0.023720, conv_measurec = 0.047719 at iteration 86800\n",
      "discriminator loss = 0.050151, generator loss = 0.023752, conv_measurec = 0.051404 at iteration 87000\n",
      "discriminator loss = 0.045706, generator loss = 0.023759, conv_measurec = 0.046588 at iteration 87200\n",
      "discriminator loss = 0.049179, generator loss = 0.023572, conv_measurec = 0.050117 at iteration 87400\n",
      "discriminator loss = 0.047055, generator loss = 0.024127, conv_measurec = 0.047625 at iteration 87600\n",
      "discriminator loss = 0.048584, generator loss = 0.023320, conv_measurec = 0.049466 at iteration 87800\n",
      "discriminator loss = 0.044081, generator loss = 0.024336, conv_measurec = 0.046345 at iteration 88000\n",
      "discriminator loss = 0.038705, generator loss = 0.023906, conv_measurec = 0.043225 at iteration 88200\n",
      "discriminator loss = 0.048328, generator loss = 0.023423, conv_measurec = 0.048964 at iteration 88400\n",
      "discriminator loss = 0.044680, generator loss = 0.024589, conv_measurec = 0.046891 at iteration 88600\n",
      "discriminator loss = 0.046206, generator loss = 0.024736, conv_measurec = 0.047800 at iteration 88800\n",
      "discriminator loss = 0.046595, generator loss = 0.024662, conv_measurec = 0.047918 at iteration 89000\n",
      "discriminator loss = 0.052581, generator loss = 0.024540, conv_measurec = 0.054203 at iteration 89200\n",
      "discriminator loss = 0.048064, generator loss = 0.024158, conv_measurec = 0.048146 at iteration 89400\n",
      "discriminator loss = 0.042906, generator loss = 0.024186, conv_measurec = 0.045594 at iteration 89600\n",
      "discriminator loss = 0.050537, generator loss = 0.024272, conv_measurec = 0.051392 at iteration 89800\n",
      "discriminator loss = 0.044280, generator loss = 0.023585, conv_measurec = 0.045677 at iteration 90000\n",
      "discriminator loss = 0.050238, generator loss = 0.024242, conv_measurec = 0.050965 at iteration 90200\n",
      "discriminator loss = 0.049290, generator loss = 0.023824, conv_measurec = 0.049959 at iteration 90400\n",
      "discriminator loss = 0.047011, generator loss = 0.023874, conv_measurec = 0.047327 at iteration 90600\n",
      "discriminator loss = 0.042094, generator loss = 0.024747, conv_measurec = 0.045738 at iteration 90800\n",
      "discriminator loss = 0.046491, generator loss = 0.024128, conv_measurec = 0.047317 at iteration 91000\n",
      "discriminator loss = 0.049363, generator loss = 0.023992, conv_measurec = 0.049880 at iteration 91200\n",
      "discriminator loss = 0.044198, generator loss = 0.024130, conv_measurec = 0.046169 at iteration 91400\n",
      "discriminator loss = 0.041571, generator loss = 0.024235, conv_measurec = 0.044959 at iteration 91600\n",
      "discriminator loss = 0.049247, generator loss = 0.024195, conv_measurec = 0.049486 at iteration 91800\n",
      "discriminator loss = 0.046457, generator loss = 0.023465, conv_measurec = 0.046631 at iteration 92000\n",
      "discriminator loss = 0.044399, generator loss = 0.023773, conv_measurec = 0.045908 at iteration 92200\n",
      "discriminator loss = 0.037348, generator loss = 0.024776, conv_measurec = 0.043380 at iteration 92400\n",
      "discriminator loss = 0.039126, generator loss = 0.024697, conv_measurec = 0.044189 at iteration 92600\n",
      "discriminator loss = 0.046282, generator loss = 0.023593, conv_measurec = 0.046664 at iteration 92800\n",
      "discriminator loss = 0.049967, generator loss = 0.024518, conv_measurec = 0.050212 at iteration 93000\n",
      "discriminator loss = 0.046626, generator loss = 0.024337, conv_measurec = 0.047574 at iteration 93200\n",
      "discriminator loss = 0.044976, generator loss = 0.023936, conv_measurec = 0.046348 at iteration 93400\n",
      "discriminator loss = 0.043831, generator loss = 0.024292, conv_measurec = 0.046129 at iteration 93600\n",
      "discriminator loss = 0.050727, generator loss = 0.024374, conv_measurec = 0.051477 at iteration 93800\n",
      "discriminator loss = 0.040769, generator loss = 0.023825, conv_measurec = 0.044130 at iteration 94000\n",
      "discriminator loss = 0.047110, generator loss = 0.023414, conv_measurec = 0.047011 at iteration 94200\n",
      "discriminator loss = 0.043582, generator loss = 0.024124, conv_measurec = 0.045831 at iteration 94400\n",
      "discriminator loss = 0.055682, generator loss = 0.024226, conv_measurec = 0.059039 at iteration 94600\n",
      "discriminator loss = 0.043631, generator loss = 0.025248, conv_measurec = 0.046972 at iteration 94800\n",
      "discriminator loss = 0.057474, generator loss = 0.024170, conv_measurec = 0.061773 at iteration 95000\n",
      "discriminator loss = 0.047114, generator loss = 0.023389, conv_measurec = 0.047018 at iteration 95200\n",
      "discriminator loss = 0.052670, generator loss = 0.024903, conv_measurec = 0.053817 at iteration 95400\n",
      "discriminator loss = 0.041882, generator loss = 0.024256, conv_measurec = 0.045103 at iteration 95600\n",
      "discriminator loss = 0.046558, generator loss = 0.024621, conv_measurec = 0.047802 at iteration 95800\n",
      "discriminator loss = 0.040709, generator loss = 0.024656, conv_measurec = 0.044911 at iteration 96000\n",
      "discriminator loss = 0.048170, generator loss = 0.023784, conv_measurec = 0.048179 at iteration 96200\n",
      "discriminator loss = 0.053296, generator loss = 0.022776, conv_measurec = 0.056882 at iteration 96400\n",
      "discriminator loss = 0.051094, generator loss = 0.023892, conv_measurec = 0.052445 at iteration 96600\n",
      "discriminator loss = 0.042602, generator loss = 0.025044, conv_measurec = 0.046237 at iteration 96800\n",
      "discriminator loss = 0.046742, generator loss = 0.024715, conv_measurec = 0.047978 at iteration 97000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.041979, generator loss = 0.023451, conv_measurec = 0.044336 at iteration 97200\n",
      "discriminator loss = 0.050183, generator loss = 0.024478, conv_measurec = 0.050462 at iteration 97400\n",
      "discriminator loss = 0.053344, generator loss = 0.025110, conv_measurec = 0.054560 at iteration 97600\n",
      "discriminator loss = 0.049966, generator loss = 0.023557, conv_measurec = 0.051063 at iteration 97800\n",
      "discriminator loss = 0.046822, generator loss = 0.025291, conv_measurec = 0.048584 at iteration 98000\n",
      "discriminator loss = 0.047256, generator loss = 0.024373, conv_measurec = 0.047884 at iteration 98200\n",
      "discriminator loss = 0.050527, generator loss = 0.024356, conv_measurec = 0.051079 at iteration 98400\n",
      "discriminator loss = 0.047859, generator loss = 0.024381, conv_measurec = 0.048190 at iteration 98600\n",
      "discriminator loss = 0.046602, generator loss = 0.023772, conv_measurec = 0.046955 at iteration 98800\n",
      "discriminator loss = 0.047633, generator loss = 0.024515, conv_measurec = 0.048208 at iteration 99000\n",
      "discriminator loss = 0.046124, generator loss = 0.024977, conv_measurec = 0.047911 at iteration 99200\n",
      "discriminator loss = 0.047640, generator loss = 0.024045, conv_measurec = 0.047740 at iteration 99400\n",
      "discriminator loss = 0.039800, generator loss = 0.025236, conv_measurec = 0.045004 at iteration 99600\n",
      "discriminator loss = 0.044140, generator loss = 0.024987, conv_measurec = 0.046924 at iteration 99800\n",
      "discriminator loss = 0.041253, generator loss = 0.024349, conv_measurec = 0.044844 at iteration 100000\n",
      "discriminator loss = 0.048604, generator loss = 0.024161, conv_measurec = 0.048350 at iteration 100200\n",
      "discriminator loss = 0.048593, generator loss = 0.023719, conv_measurec = 0.048779 at iteration 100400\n",
      "discriminator loss = 0.045598, generator loss = 0.023849, conv_measurec = 0.046514 at iteration 100600\n",
      "discriminator loss = 0.051933, generator loss = 0.023779, conv_measurec = 0.053716 at iteration 100800\n",
      "discriminator loss = 0.045969, generator loss = 0.024414, conv_measurec = 0.047259 at iteration 101000\n",
      "discriminator loss = 0.054478, generator loss = 0.024783, conv_measurec = 0.056503 at iteration 101200\n",
      "discriminator loss = 0.050850, generator loss = 0.024760, conv_measurec = 0.051080 at iteration 101400\n",
      "discriminator loss = 0.048638, generator loss = 0.023957, conv_measurec = 0.048572 at iteration 101600\n",
      "discriminator loss = 0.040717, generator loss = 0.023902, conv_measurec = 0.044118 at iteration 101800\n",
      "discriminator loss = 0.046392, generator loss = 0.023635, conv_measurec = 0.046688 at iteration 102000\n",
      "discriminator loss = 0.043909, generator loss = 0.024111, conv_measurec = 0.045918 at iteration 102200\n",
      "discriminator loss = 0.047564, generator loss = 0.024294, conv_measurec = 0.047925 at iteration 102400\n",
      "discriminator loss = 0.048905, generator loss = 0.023889, conv_measurec = 0.049019 at iteration 102600\n",
      "discriminator loss = 0.046406, generator loss = 0.024109, conv_measurec = 0.047159 at iteration 102800\n",
      "discriminator loss = 0.046698, generator loss = 0.023803, conv_measurec = 0.047000 at iteration 103000\n",
      "discriminator loss = 0.053053, generator loss = 0.023418, conv_measurec = 0.055703 at iteration 103200\n",
      "discriminator loss = 0.051485, generator loss = 0.024217, conv_measurec = 0.052533 at iteration 103400\n",
      "discriminator loss = 0.044409, generator loss = 0.023826, conv_measurec = 0.045873 at iteration 103600\n",
      "discriminator loss = 0.040973, generator loss = 0.023928, conv_measurec = 0.044254 at iteration 103800\n",
      "discriminator loss = 0.051385, generator loss = 0.024884, conv_measurec = 0.051688 at iteration 104000\n",
      "discriminator loss = 0.050340, generator loss = 0.024419, conv_measurec = 0.050590 at iteration 104200\n",
      "discriminator loss = 0.052948, generator loss = 0.025277, conv_measurec = 0.053621 at iteration 104400\n",
      "discriminator loss = 0.050536, generator loss = 0.024563, conv_measurec = 0.050730 at iteration 104600\n",
      "discriminator loss = 0.045478, generator loss = 0.024519, conv_measurec = 0.047086 at iteration 104800\n",
      "discriminator loss = 0.047495, generator loss = 0.025200, conv_measurec = 0.048768 at iteration 105000\n",
      "discriminator loss = 0.042293, generator loss = 0.024061, conv_measurec = 0.045035 at iteration 105200\n",
      "discriminator loss = 0.043682, generator loss = 0.023650, conv_measurec = 0.045320 at iteration 105400\n",
      "discriminator loss = 0.057833, generator loss = 0.023823, conv_measurec = 0.062403 at iteration 105600\n",
      "discriminator loss = 0.042146, generator loss = 0.023351, conv_measurec = 0.044252 at iteration 105800\n",
      "discriminator loss = 0.045151, generator loss = 0.023564, conv_measurec = 0.045964 at iteration 106000\n",
      "discriminator loss = 0.046837, generator loss = 0.023655, conv_measurec = 0.046897 at iteration 106200\n",
      "discriminator loss = 0.048872, generator loss = 0.024816, conv_measurec = 0.049064 at iteration 106400\n",
      "discriminator loss = 0.053593, generator loss = 0.024500, conv_measurec = 0.055326 at iteration 106600\n",
      "discriminator loss = 0.048443, generator loss = 0.023820, conv_measurec = 0.048293 at iteration 106800\n",
      "discriminator loss = 0.051385, generator loss = 0.024830, conv_measurec = 0.051668 at iteration 107000\n",
      "discriminator loss = 0.046849, generator loss = 0.023931, conv_measurec = 0.047167 at iteration 107200\n",
      "discriminator loss = 0.047780, generator loss = 0.023989, conv_measurec = 0.047689 at iteration 107400\n",
      "discriminator loss = 0.048870, generator loss = 0.023932, conv_measurec = 0.048800 at iteration 107600\n",
      "discriminator loss = 0.050027, generator loss = 0.024288, conv_measurec = 0.050167 at iteration 107800\n",
      "discriminator loss = 0.054704, generator loss = 0.023366, conv_measurec = 0.058121 at iteration 108000\n",
      "discriminator loss = 0.041696, generator loss = 0.024204, conv_measurec = 0.044854 at iteration 108200\n",
      "discriminator loss = 0.043768, generator loss = 0.024596, conv_measurec = 0.046277 at iteration 108400\n",
      "discriminator loss = 0.046979, generator loss = 0.024005, conv_measurec = 0.047295 at iteration 108600\n",
      "discriminator loss = 0.055388, generator loss = 0.024832, conv_measurec = 0.057624 at iteration 108800\n",
      "discriminator loss = 0.051758, generator loss = 0.023966, conv_measurec = 0.053061 at iteration 109000\n",
      "discriminator loss = 0.048067, generator loss = 0.024224, conv_measurec = 0.048052 at iteration 109200\n",
      "discriminator loss = 0.041952, generator loss = 0.024036, conv_measurec = 0.044805 at iteration 109400\n",
      "discriminator loss = 0.047204, generator loss = 0.024328, conv_measurec = 0.047719 at iteration 109600\n",
      "discriminator loss = 0.048706, generator loss = 0.023692, conv_measurec = 0.048746 at iteration 109800\n",
      "discriminator loss = 0.048700, generator loss = 0.024294, conv_measurec = 0.048429 at iteration 110000\n",
      "discriminator loss = 0.057391, generator loss = 0.024599, conv_measurec = 0.060832 at iteration 110200\n",
      "discriminator loss = 0.043109, generator loss = 0.023346, conv_measurec = 0.044692 at iteration 110400\n",
      "discriminator loss = 0.042578, generator loss = 0.024037, conv_measurec = 0.045109 at iteration 110600\n",
      "discriminator loss = 0.044943, generator loss = 0.024323, conv_measurec = 0.046574 at iteration 110800\n",
      "discriminator loss = 0.053885, generator loss = 0.023739, conv_measurec = 0.056438 at iteration 111000\n",
      "discriminator loss = 0.056747, generator loss = 0.023841, conv_measurec = 0.060623 at iteration 111200\n",
      "discriminator loss = 0.040575, generator loss = 0.024045, conv_measurec = 0.044109 at iteration 111400\n",
      "discriminator loss = 0.049741, generator loss = 0.024092, conv_measurec = 0.049844 at iteration 111600\n",
      "discriminator loss = 0.049073, generator loss = 0.024132, conv_measurec = 0.048795 at iteration 111800\n",
      "discriminator loss = 0.044311, generator loss = 0.024134, conv_measurec = 0.046061 at iteration 112000\n",
      "discriminator loss = 0.055400, generator loss = 0.023632, conv_measurec = 0.058791 at iteration 112200\n",
      "discriminator loss = 0.046089, generator loss = 0.024226, conv_measurec = 0.047037 at iteration 112400\n",
      "discriminator loss = 0.044768, generator loss = 0.024537, conv_measurec = 0.046684 at iteration 112600\n",
      "discriminator loss = 0.057494, generator loss = 0.023656, conv_measurec = 0.061895 at iteration 112800\n",
      "discriminator loss = 0.045244, generator loss = 0.023813, conv_measurec = 0.046201 at iteration 113000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.046281, generator loss = 0.024567, conv_measurec = 0.047465 at iteration 113200\n",
      "discriminator loss = 0.047545, generator loss = 0.024444, conv_measurec = 0.047973 at iteration 113400\n",
      "discriminator loss = 0.043393, generator loss = 0.025256, conv_measurec = 0.046700 at iteration 113600\n",
      "discriminator loss = 0.042399, generator loss = 0.025117, conv_measurec = 0.046063 at iteration 113800\n",
      "discriminator loss = 0.046530, generator loss = 0.025434, conv_measurec = 0.048440 at iteration 114000\n",
      "discriminator loss = 0.044840, generator loss = 0.023509, conv_measurec = 0.045689 at iteration 114200\n",
      "discriminator loss = 0.052279, generator loss = 0.024020, conv_measurec = 0.053658 at iteration 114400\n",
      "discriminator loss = 0.041205, generator loss = 0.023839, conv_measurec = 0.044195 at iteration 114600\n",
      "discriminator loss = 0.049221, generator loss = 0.024579, conv_measurec = 0.048933 at iteration 114800\n",
      "discriminator loss = 0.043479, generator loss = 0.024110, conv_measurec = 0.045597 at iteration 115000\n",
      "discriminator loss = 0.045549, generator loss = 0.024051, conv_measurec = 0.046571 at iteration 115200\n",
      "discriminator loss = 0.049636, generator loss = 0.023668, conv_measurec = 0.050031 at iteration 115400\n",
      "discriminator loss = 0.044443, generator loss = 0.024151, conv_measurec = 0.046114 at iteration 115600\n",
      "discriminator loss = 0.053242, generator loss = 0.024092, conv_measurec = 0.054991 at iteration 115800\n",
      "discriminator loss = 0.042169, generator loss = 0.024197, conv_measurec = 0.045019 at iteration 116000\n",
      "discriminator loss = 0.041722, generator loss = 0.024548, conv_measurec = 0.045142 at iteration 116200\n",
      "discriminator loss = 0.048649, generator loss = 0.023038, conv_measurec = 0.049176 at iteration 116400\n",
      "discriminator loss = 0.048458, generator loss = 0.024374, conv_measurec = 0.048333 at iteration 116600\n",
      "discriminator loss = 0.045812, generator loss = 0.024998, conv_measurec = 0.047625 at iteration 116800\n",
      "discriminator loss = 0.044464, generator loss = 0.023696, conv_measurec = 0.045663 at iteration 117000\n",
      "discriminator loss = 0.040772, generator loss = 0.023949, conv_measurec = 0.044065 at iteration 117200\n",
      "discriminator loss = 0.045894, generator loss = 0.025014, conv_measurec = 0.047677 at iteration 117400\n",
      "discriminator loss = 0.049954, generator loss = 0.025071, conv_measurec = 0.049763 at iteration 117600\n",
      "discriminator loss = 0.051164, generator loss = 0.025437, conv_measurec = 0.050728 at iteration 117800\n",
      "discriminator loss = 0.048643, generator loss = 0.023703, conv_measurec = 0.048442 at iteration 118000\n",
      "discriminator loss = 0.052154, generator loss = 0.024341, conv_measurec = 0.053044 at iteration 118200\n",
      "discriminator loss = 0.042416, generator loss = 0.023937, conv_measurec = 0.044865 at iteration 118400\n",
      "discriminator loss = 0.047873, generator loss = 0.024588, conv_measurec = 0.048237 at iteration 118600\n",
      "discriminator loss = 0.043489, generator loss = 0.024497, conv_measurec = 0.045953 at iteration 118800\n",
      "discriminator loss = 0.046657, generator loss = 0.024691, conv_measurec = 0.047726 at iteration 119000\n",
      "discriminator loss = 0.044160, generator loss = 0.023328, conv_measurec = 0.045130 at iteration 119200\n",
      "discriminator loss = 0.045964, generator loss = 0.024157, conv_measurec = 0.046850 at iteration 119400\n",
      "discriminator loss = 0.047290, generator loss = 0.024087, conv_measurec = 0.047442 at iteration 119600\n",
      "discriminator loss = 0.044031, generator loss = 0.024884, conv_measurec = 0.046597 at iteration 119800\n",
      "discriminator loss = 0.050639, generator loss = 0.023696, conv_measurec = 0.051395 at iteration 120000\n",
      "discriminator loss = 0.048480, generator loss = 0.024442, conv_measurec = 0.048383 at iteration 120200\n",
      "discriminator loss = 0.044720, generator loss = 0.023942, conv_measurec = 0.046007 at iteration 120400\n",
      "discriminator loss = 0.054010, generator loss = 0.023936, conv_measurec = 0.056187 at iteration 120600\n",
      "discriminator loss = 0.050519, generator loss = 0.023872, conv_measurec = 0.051014 at iteration 120800\n",
      "discriminator loss = 0.047161, generator loss = 0.024677, conv_measurec = 0.047948 at iteration 121000\n",
      "discriminator loss = 0.040060, generator loss = 0.024439, conv_measurec = 0.044162 at iteration 121200\n",
      "discriminator loss = 0.039665, generator loss = 0.025265, conv_measurec = 0.044778 at iteration 121400\n",
      "discriminator loss = 0.050506, generator loss = 0.024646, conv_measurec = 0.050172 at iteration 121600\n",
      "discriminator loss = 0.048670, generator loss = 0.024000, conv_measurec = 0.048084 at iteration 121800\n",
      "discriminator loss = 0.047799, generator loss = 0.024542, conv_measurec = 0.048126 at iteration 122000\n",
      "discriminator loss = 0.043974, generator loss = 0.023323, conv_measurec = 0.045008 at iteration 122200\n",
      "discriminator loss = 0.046708, generator loss = 0.023887, conv_measurec = 0.046930 at iteration 122400\n",
      "discriminator loss = 0.047336, generator loss = 0.024011, conv_measurec = 0.047365 at iteration 122600\n",
      "discriminator loss = 0.050613, generator loss = 0.023648, conv_measurec = 0.051341 at iteration 122800\n",
      "discriminator loss = 0.046888, generator loss = 0.024234, conv_measurec = 0.047358 at iteration 123000\n",
      "discriminator loss = 0.050178, generator loss = 0.023886, conv_measurec = 0.050431 at iteration 123200\n",
      "discriminator loss = 0.049251, generator loss = 0.024343, conv_measurec = 0.048643 at iteration 123400\n",
      "discriminator loss = 0.057477, generator loss = 0.024110, conv_measurec = 0.061138 at iteration 123600\n",
      "discriminator loss = 0.045818, generator loss = 0.024000, conv_measurec = 0.046586 at iteration 123800\n",
      "discriminator loss = 0.045607, generator loss = 0.023932, conv_measurec = 0.046412 at iteration 124000\n",
      "discriminator loss = 0.047929, generator loss = 0.024121, conv_measurec = 0.047757 at iteration 124200\n",
      "discriminator loss = 0.048436, generator loss = 0.024116, conv_measurec = 0.048005 at iteration 124400\n",
      "discriminator loss = 0.047792, generator loss = 0.024231, conv_measurec = 0.047794 at iteration 124600\n",
      "discriminator loss = 0.061912, generator loss = 0.024798, conv_measurec = 0.067042 at iteration 124800\n",
      "discriminator loss = 0.045898, generator loss = 0.024588, conv_measurec = 0.047196 at iteration 125000\n",
      "discriminator loss = 0.043802, generator loss = 0.023651, conv_measurec = 0.045222 at iteration 125200\n",
      "discriminator loss = 0.054580, generator loss = 0.024527, conv_measurec = 0.056312 at iteration 125400\n",
      "discriminator loss = 0.046013, generator loss = 0.024469, conv_measurec = 0.047131 at iteration 125600\n",
      "discriminator loss = 0.043055, generator loss = 0.024314, conv_measurec = 0.045498 at iteration 125800\n",
      "discriminator loss = 0.041455, generator loss = 0.024178, conv_measurec = 0.044562 at iteration 126000\n",
      "discriminator loss = 0.044893, generator loss = 0.024180, conv_measurec = 0.046281 at iteration 126200\n",
      "discriminator loss = 0.046719, generator loss = 0.023708, conv_measurec = 0.046727 at iteration 126400\n",
      "discriminator loss = 0.045625, generator loss = 0.023860, conv_measurec = 0.046329 at iteration 126600\n",
      "discriminator loss = 0.046941, generator loss = 0.023488, conv_measurec = 0.046618 at iteration 126800\n",
      "discriminator loss = 0.045220, generator loss = 0.023618, conv_measurec = 0.045885 at iteration 127000\n",
      "discriminator loss = 0.036527, generator loss = 0.024307, conv_measurec = 0.042215 at iteration 127200\n",
      "discriminator loss = 0.054247, generator loss = 0.024858, conv_measurec = 0.055419 at iteration 127400\n",
      "discriminator loss = 0.043818, generator loss = 0.023738, conv_measurec = 0.045297 at iteration 127600\n",
      "discriminator loss = 0.046412, generator loss = 0.024795, conv_measurec = 0.047634 at iteration 127800\n",
      "discriminator loss = 0.048381, generator loss = 0.025100, conv_measurec = 0.048917 at iteration 128000\n",
      "discriminator loss = 0.048341, generator loss = 0.023907, conv_measurec = 0.047720 at iteration 128200\n",
      "discriminator loss = 0.050824, generator loss = 0.023968, conv_measurec = 0.051188 at iteration 128400\n",
      "discriminator loss = 0.046389, generator loss = 0.024272, conv_measurec = 0.047100 at iteration 128600\n",
      "discriminator loss = 0.049844, generator loss = 0.023676, conv_measurec = 0.050012 at iteration 128800\n",
      "discriminator loss = 0.047758, generator loss = 0.024992, conv_measurec = 0.048490 at iteration 129000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss = 0.049307, generator loss = 0.025567, conv_measurec = 0.049829 at iteration 129200\n",
      "discriminator loss = 0.044766, generator loss = 0.024413, conv_measurec = 0.046421 at iteration 129400\n",
      "discriminator loss = 0.039373, generator loss = 0.023844, conv_measurec = 0.043163 at iteration 129600\n",
      "discriminator loss = 0.049021, generator loss = 0.024589, conv_measurec = 0.048718 at iteration 129800\n",
      "discriminator loss = 0.045321, generator loss = 0.023013, conv_measurec = 0.045315 at iteration 130000\n",
      "discriminator loss = 0.046883, generator loss = 0.024214, conv_measurec = 0.047278 at iteration 130200\n",
      "discriminator loss = 0.047285, generator loss = 0.024613, conv_measurec = 0.047869 at iteration 130400\n",
      "discriminator loss = 0.053262, generator loss = 0.024293, conv_measurec = 0.054450 at iteration 130600\n",
      "discriminator loss = 0.048720, generator loss = 0.023477, conv_measurec = 0.048488 at iteration 130800\n",
      "discriminator loss = 0.043576, generator loss = 0.023922, conv_measurec = 0.045329 at iteration 131000\n",
      "discriminator loss = 0.051189, generator loss = 0.023375, conv_measurec = 0.052289 at iteration 131200\n",
      "discriminator loss = 0.044928, generator loss = 0.023172, conv_measurec = 0.045264 at iteration 131400\n",
      "discriminator loss = 0.050919, generator loss = 0.024231, conv_measurec = 0.050976 at iteration 131600\n",
      "discriminator loss = 0.049990, generator loss = 0.024782, conv_measurec = 0.049376 at iteration 131800\n",
      "discriminator loss = 0.047691, generator loss = 0.024180, conv_measurec = 0.047633 at iteration 132000\n",
      "discriminator loss = 0.042777, generator loss = 0.024372, conv_measurec = 0.045362 at iteration 132200\n",
      "discriminator loss = 0.047176, generator loss = 0.024341, conv_measurec = 0.047530 at iteration 132400\n",
      "discriminator loss = 0.050064, generator loss = 0.024811, conv_measurec = 0.049435 at iteration 132600\n",
      "discriminator loss = 0.044885, generator loss = 0.024380, conv_measurec = 0.046420 at iteration 132800\n",
      "discriminator loss = 0.042251, generator loss = 0.024198, conv_measurec = 0.044921 at iteration 133000\n",
      "discriminator loss = 0.049937, generator loss = 0.024506, conv_measurec = 0.049176 at iteration 133200\n",
      "discriminator loss = 0.047128, generator loss = 0.023832, conv_measurec = 0.046998 at iteration 133400\n",
      "discriminator loss = 0.045056, generator loss = 0.023429, conv_measurec = 0.045564 at iteration 133600\n",
      "discriminator loss = 0.038020, generator loss = 0.024023, conv_measurec = 0.042627 at iteration 133800\n",
      "discriminator loss = 0.039780, generator loss = 0.023500, conv_measurec = 0.042992 at iteration 134000\n",
      "discriminator loss = 0.046973, generator loss = 0.024426, conv_measurec = 0.047497 at iteration 134200\n",
      "discriminator loss = 0.050644, generator loss = 0.024179, conv_measurec = 0.050551 at iteration 134400\n",
      "discriminator loss = 0.047300, generator loss = 0.024075, conv_measurec = 0.047312 at iteration 134600\n",
      "discriminator loss = 0.045665, generator loss = 0.024435, conv_measurec = 0.046847 at iteration 134800\n",
      "discriminator loss = 0.044489, generator loss = 0.023599, conv_measurec = 0.045436 at iteration 135000\n",
      "discriminator loss = 0.051403, generator loss = 0.024128, conv_measurec = 0.051723 at iteration 135200\n",
      "discriminator loss = 0.041443, generator loss = 0.023936, conv_measurec = 0.044240 at iteration 135400\n",
      "discriminator loss = 0.047762, generator loss = 0.023262, conv_measurec = 0.047162 at iteration 135600\n",
      "discriminator loss = 0.044264, generator loss = 0.024227, conv_measurec = 0.045934 at iteration 135800\n",
      "discriminator loss = 0.056358, generator loss = 0.024121, conv_measurec = 0.059145 at iteration 136000\n",
      "discriminator loss = 0.044333, generator loss = 0.025028, conv_measurec = 0.046752 at iteration 136200\n",
      "discriminator loss = 0.058118, generator loss = 0.023173, conv_measurec = 0.062770 at iteration 136400\n",
      "discriminator loss = 0.047829, generator loss = 0.025002, conv_measurec = 0.048471 at iteration 136600\n",
      "discriminator loss = 0.053326, generator loss = 0.023671, conv_measurec = 0.055049 at iteration 136800\n",
      "discriminator loss = 0.042587, generator loss = 0.024902, conv_measurec = 0.045749 at iteration 137000\n",
      "discriminator loss = 0.047230, generator loss = 0.024075, conv_measurec = 0.047256 at iteration 137200\n",
      "discriminator loss = 0.041379, generator loss = 0.024011, conv_measurec = 0.044266 at iteration 137400\n",
      "discriminator loss = 0.048855, generator loss = 0.024213, conv_measurec = 0.048201 at iteration 137600\n",
      "discriminator loss = 0.053966, generator loss = 0.023595, conv_measurec = 0.056063 at iteration 137800\n",
      "discriminator loss = 0.051797, generator loss = 0.024729, conv_measurec = 0.051608 at iteration 138000\n",
      "discriminator loss = 0.043275, generator loss = 0.024201, conv_measurec = 0.045394 at iteration 138200\n",
      "discriminator loss = 0.047377, generator loss = 0.023091, conv_measurec = 0.046698 at iteration 138400\n",
      "discriminator loss = 0.042690, generator loss = 0.024838, conv_measurec = 0.045724 at iteration 138600\n",
      "discriminator loss = 0.050886, generator loss = 0.024884, conv_measurec = 0.050057 at iteration 138800\n",
      "discriminator loss = 0.054018, generator loss = 0.024260, conv_measurec = 0.055410 at iteration 139000\n",
      "discriminator loss = 0.050672, generator loss = 0.024723, conv_measurec = 0.049897 at iteration 139200\n",
      "discriminator loss = 0.047526, generator loss = 0.025097, conv_measurec = 0.048390 at iteration 139400\n",
      "discriminator loss = 0.047930, generator loss = 0.024091, conv_measurec = 0.047602 at iteration 139600\n",
      "discriminator loss = 0.051182, generator loss = 0.023577, conv_measurec = 0.051858 at iteration 139800\n",
      "discriminator loss = 0.048527, generator loss = 0.023944, conv_measurec = 0.047753 at iteration 140000\n",
      "discriminator loss = 0.047288, generator loss = 0.024238, conv_measurec = 0.047421 at iteration 140200\n",
      "discriminator loss = 0.048318, generator loss = 0.024417, conv_measurec = 0.048109 at iteration 140400\n",
      "discriminator loss = 0.046811, generator loss = 0.024593, conv_measurec = 0.047527 at iteration 140600\n",
      "discriminator loss = 0.048342, generator loss = 0.024728, conv_measurec = 0.048423 at iteration 140800\n",
      "discriminator loss = 0.040490, generator loss = 0.024763, conv_measurec = 0.044531 at iteration 141000\n",
      "discriminator loss = 0.044839, generator loss = 0.024902, conv_measurec = 0.046838 at iteration 141200\n",
      "discriminator loss = 0.041914, generator loss = 0.023750, conv_measurec = 0.044245 at iteration 141400\n",
      "discriminator loss = 0.049278, generator loss = 0.024013, conv_measurec = 0.048497 at iteration 141600\n",
      "discriminator loss = 0.049318, generator loss = 0.025186, conv_measurec = 0.049352 at iteration 141800\n",
      "discriminator loss = 0.046298, generator loss = 0.024598, conv_measurec = 0.047263 at iteration 142000\n",
      "discriminator loss = 0.052585, generator loss = 0.023368, conv_measurec = 0.054127 at iteration 142200\n",
      "discriminator loss = 0.046648, generator loss = 0.024233, conv_measurec = 0.047077 at iteration 142400\n",
      "discriminator loss = 0.055152, generator loss = 0.024215, conv_measurec = 0.057071 at iteration 142600\n",
      "discriminator loss = 0.051529, generator loss = 0.024339, conv_measurec = 0.051501 at iteration 142800\n",
      "discriminator loss = 0.049355, generator loss = 0.025064, conv_measurec = 0.049241 at iteration 143000\n",
      "discriminator loss = 0.041393, generator loss = 0.024012, conv_measurec = 0.044227 at iteration 143200\n",
      "discriminator loss = 0.047105, generator loss = 0.024853, conv_measurec = 0.047905 at iteration 143400\n",
      "discriminator loss = 0.044637, generator loss = 0.025355, conv_measurec = 0.047161 at iteration 143600\n",
      "discriminator loss = 0.048232, generator loss = 0.023953, conv_measurec = 0.047584 at iteration 143800\n",
      "discriminator loss = 0.049587, generator loss = 0.024190, conv_measurec = 0.048718 at iteration 144000\n",
      "discriminator loss = 0.047071, generator loss = 0.023817, conv_measurec = 0.046868 at iteration 144200\n",
      "discriminator loss = 0.047372, generator loss = 0.023935, conv_measurec = 0.047131 at iteration 144400\n",
      "discriminator loss = 0.053752, generator loss = 0.024420, conv_measurec = 0.054701 at iteration 144600\n",
      "discriminator loss = 0.052170, generator loss = 0.024357, conv_measurec = 0.052394 at iteration 144800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-be7a6dd8a791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(\"update param\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbalance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreal_loss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfake_loss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m#balance = 0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(balance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/venv/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(1000):\n",
    "    train_data.reset()\n",
    "    for batch in train_data:\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        latent_z = mx.nd.uniform(-1, 1, shape=(param['batch_size'],param['latent_z_size'] ), ctx=ctx)\n",
    "        \n",
    "        ##Discriminator loss\n",
    "        #print(\"dis_loss\")\n",
    "        with autograd.record():\n",
    "            gen_z = gen(latent_z)\n",
    "            outputs_d_z = disc(gen_z.detach())\n",
    "            outputs_d_x = disc(data)\n",
    "            real_loss_d, fake_loss_d = disc_loss(outputs_d_x, data, outputs_d_z, gen_z)\n",
    "            lossD = real_loss_d - param['k'] * fake_loss_d\n",
    "            lossD.backward()\n",
    "        train_disc.step(param['batch_size'])\n",
    "        \n",
    "        ##Generative loss\n",
    "        with autograd.record():\n",
    "            gen_z = gen(latent_z)\n",
    "            outputs_g_z = disc(gen_z)\n",
    "            lossG = gen_loss(outputs_g_z,gen_z)\n",
    "            lossG.backward()\n",
    "        train_gen.step(param['batch_size'])\n",
    "        \n",
    "        ##adjust learning rate\n",
    "        if iter % 3000 == 0:\n",
    "            lr_scheduler.learning_rate = lr_scheduler.learning_rate * (0.95**(iter//3000))\n",
    "        \n",
    "        balance = param['gamma']*real_loss_d.asscalar() - fake_loss_d.asscalar()\n",
    "\n",
    "        param['k'] = param['k']  + param['lambda_k'] * balance\n",
    "\n",
    "        conv_measure = real_loss_d.asscalar() + np.abs(balance)\n",
    "        if iter % 100 == 0:\n",
    "            iter_loss['lossD'].append(nd.mean(lossD).asscalar())\n",
    "            iter_loss['lossG'].append(nd.mean(lossG).asscalar())\n",
    "            iter_loss['conv_measure'].append(conv_measure)\n",
    "        if iter % 200 == 0:\n",
    "            print('discriminator loss = %f, generator loss = %f, conv_measurec = %f at iteration %d' %(iter_loss['lossD'][-1],iter_loss['lossG'][-1], iter_loss['conv_measure'][-1], iter))\n",
    "        if iter % 5000 == 0:\n",
    "            model_prefix = os.getcwd()+'/model/gen_model_iter_' + str(iter)\n",
    "            gen.save_params(model_prefix)\n",
    "        iter = iter +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = os.getcwd()+'/began_perform_' + str(iter)\n",
    "gen.save_params(model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/skinet/work/gluon_code'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 =  Decoder(param)\n",
    "gen2.load_params('began_perform_' + str(iter),ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAD7CAYAAABHYA6MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ff589e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(num_image):\n",
    "    latent_z = mx.nd.uniform(-1, 1, shape=(param['batch_size'],param['latent_z_size'] ), ctx=ctx)\n",
    "    img = gen2(latent_z)\n",
    "    #img = gen(latent_z)\n",
    "    plt.subplot(3,4,i+1)\n",
    "    visualize(img[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
